{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f081225a",
   "metadata": {
    "papermill": {
     "duration": 0.003331,
     "end_time": "2023-12-14T13:57:26.206261",
     "exception": false,
     "start_time": "2023-12-14T13:57:26.202930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DSCI-598 Capstone\n",
    "## Maryville University\n",
    "### November - December 2023\n",
    "### Alison Hawke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b2691",
   "metadata": {
    "papermill": {
     "duration": 0.002449,
     "end_time": "2023-12-14T13:57:26.211601",
     "exception": false,
     "start_time": "2023-12-14T13:57:26.209152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Final submission notebook \n",
    "\n",
    "Through the six weeks of this project, I have explored several models to predict the cover type of a given piece of land based on the available factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de99fa",
   "metadata": {
    "papermill": {
     "duration": 0.00233,
     "end_time": "2023-12-14T13:57:26.218314",
     "exception": false,
     "start_time": "2023-12-14T13:57:26.215984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Links to my notebooks\n",
    "\n",
    "* [Data visualisation and analysis](https://www.kaggle.com/alisonhawke/dsci-598-data-visualisations)\n",
    "* [Four models](https://www.kaggle.com/alisonhawke/dsci-598-four-models) containing:\n",
    "    * Logical regression\n",
    "    * Logical regression with cross validation\n",
    "    * Decision tree\n",
    "    * Random Forest (score: 0.73306)\n",
    "* [Random Forest with Principal Component Analysis](https://www.kaggle.com/code/alisonhawke/dsci-598-principal-component-analysis) (score: 0.73977)\n",
    "* [Support Vector Machine](https://www.kaggle.com/alisonhawke/dsci-598-svm) (score: 0.58006)\n",
    "* [K Nearest Neighbours](https://www.kaggle.com/code/alisonhawke/dsci-598-k-nearest-neighbours) (score: 0.61554)\n",
    "* [Neural Network](https://www.kaggle.com/code/alisonhawke/dsci-598-neural-network) (score: 0.52131)\n",
    "* [XGBoost Classifier](https://www.kaggle.com/alisonhawke/dsci-598-xgboost) (score 0.71989)\n",
    "* [XGBoost parameter tuning](https://www.kaggle.com/code/alisonhawke/dsci-598-xgboost2) (score  0.73775)\n",
    "* [Extra Trees with feature changes](https://www.kaggle.com/alisonhawke/dsci-598-feature-changes) (score 0.77866)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3207fe6",
   "metadata": {
    "papermill": {
     "duration": 0.002264,
     "end_time": "2023-12-14T13:57:26.223132",
     "exception": false,
     "start_time": "2023-12-14T13:57:26.220868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Best models\n",
    "\n",
    "As the above scores show, the Extra Trees model, after feature engineering, gave the highest submission accuracy of 77.87%\n",
    "\n",
    "The Random Forest model with principal component analysis was slightly less accurate, with a submission of 73.98%.\n",
    "\n",
    "The XGBoost model predicting the test set with a submission score of 73.78%. Parameter tuning increased its accuracy on the training set by 6%, a significant margin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f944bc85",
   "metadata": {
    "papermill": {
     "duration": 0.002278,
     "end_time": "2023-12-14T13:57:26.227933",
     "exception": false,
     "start_time": "2023-12-14T13:57:26.225655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Issues during this project\n",
    "\n",
    "I ran into difficulty in trying to reverse the one-hot encoding in the dataset. Neither method I tried worked on a Kaggle-run notebook, one method did work on a local notebook. I ended up not needing this but it was a useful exercise to manipulate the data.\n",
    "\n",
    "The Forest Cover data set is highly curated, and as such, does not show the same missing values and uneven distribution you woudl expect in a more realistic data set. This was both good and bad, as it allowed me to focus more on comparing models than data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd81ed",
   "metadata": {
    "papermill": {
     "duration": 0.002301,
     "end_time": "2023-12-14T13:57:26.232709",
     "exception": false,
     "start_time": "2023-12-14T13:57:26.230408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusions:\n",
    "\n",
    "Feature engineering was the most successful in boosting the model accuracy, in particular combining correlated features.\n",
    "\n",
    "Parameter-tuning models increased their score by up to 6%, a significant increase in accuracy.\n",
    "\n",
    "Models may have a diminishing returns point, whereby adding increased iterations does not improve accuracy beyond a certain point. This is a useful reminder that more is not always better. In these cases, exploring around a \"1, 2, 5\" pattern may help. For example:\n",
    "\n",
    "* 1, 2, and 5 iterations\n",
    "* 10, 20, and 50 iterations\n",
    "* 100, 200, and 500 iterations\n",
    "* 1000, 2000, and 5000 iterations\n",
    "\n",
    "And so forth.\n",
    "\n",
    "XGBoost and Extra Trees were new models I investigated for this capstone project, both have advantages to other models I tried. As with other fields, the best selection of a tool will depend on the job you wish to accomplish, and how much complexity you with to take on.\n",
    "\n",
    "The Forest Cover dataset is extremely well-curated to be balanced, with all cover types equally represented in the training data. This would not be the case with many real-world data sets. Data cleaning and feature engineering are skills that would be necessary to get a decent data set to work with."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 137277,
     "sourceId": 3936,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.989054,
   "end_time": "2023-12-14T13:57:26.555111",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-14T13:57:22.566057",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
